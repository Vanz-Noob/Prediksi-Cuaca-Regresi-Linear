{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "File \u001b[1;32mc:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\pandas\\__init__.py:148\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28meval\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    132\u001b[0m     concat,\n\u001b[0;32m    133\u001b[0m     lreshape,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m     qcut,\n\u001b[0;32m    146\u001b[0m )\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_print_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "File \u001b[1;32mc:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\pandas\\api\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" public toolkit API \"\"\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     extensions,\n\u001b[0;32m      4\u001b[0m     indexers,\n\u001b[0;32m      5\u001b[0m     interchange,\n\u001b[0;32m      6\u001b[0m     types,\n\u001b[0;32m      7\u001b[0m     typing,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterchange\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextensions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtyping\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\pandas\\api\\typing\\__init__.py:31\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwindow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     Expanding,\n\u001b[0;32m     21\u001b[0m     ExpandingGroupby,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     Window,\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# TODO: Can't import Styler without importing jinja2\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# from pandas.io.formats.style import Styler\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_json\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonReader\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StataReader\n\u001b[0;32m     34\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrameGroupBy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatetimeIndexResamplerGroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\pandas\\io\\json\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_json\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     read_json,\n\u001b[0;32m      3\u001b[0m     to_json,\n\u001b[0;32m      4\u001b[0m     ujson_dumps \u001b[38;5;28;01mas\u001b[39;00m dumps,\n\u001b[0;32m      5\u001b[0m     ujson_loads \u001b[38;5;28;01mas\u001b[39;00m loads,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_table_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_table_schema\n\u001b[0;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdumps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_table_schema\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\pandas\\io\\json\\_json.py:67\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_normalize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_line_delimits\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_table_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     64\u001b[0m     build_table_schema,\n\u001b[0;32m     65\u001b[0m     parse_table_schema,\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_integer\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     71\u001b[0m         Hashable,\n\u001b[0;32m     72\u001b[0m         Mapping,\n\u001b[0;32m     73\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     TextFileReader,\n\u001b[0;32m      3\u001b[0m     TextParser,\n\u001b[0;32m      4\u001b[0m     read_csv,\n\u001b[0;32m      5\u001b[0m     read_fwf,\n\u001b[0;32m      6\u001b[0m     read_table,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextFileReader\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextParser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_fwf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_table\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STR_NA_VALUES\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     AbstractMethodError,\n\u001b[0;32m     30\u001b[0m     ParserWarning,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Appender\n",
      "File \u001b[1;32mparsers.pyx:1417\u001b[0m, in \u001b[0;36minit pandas._libs.parsers\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_parser_CAPI' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "36/36 [==============================] - 1s 4ms/step - loss: 2422.5403 - accuracy: 0.0141\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2404.2893 - accuracy: 0.0141\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2385.9453 - accuracy: 0.0141\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2366.6357 - accuracy: 0.0141\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2347.4250 - accuracy: 0.0141\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2327.3271 - accuracy: 0.0141\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 1000us/step - loss: 2307.1240 - accuracy: 0.0141\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2284.7644 - accuracy: 0.0141\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 971us/step - loss: 2262.9719 - accuracy: 0.0141\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 971us/step - loss: 2240.0967 - accuracy: 0.0141\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 971us/step - loss: 2217.0879 - accuracy: 0.0141\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2193.1357 - accuracy: 0.0141\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2168.2402 - accuracy: 0.0141\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2143.6753 - accuracy: 0.0141\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 2117.4612 - accuracy: 0.0141\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 971us/step - loss: 2090.7456 - accuracy: 0.0141\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 971us/step - loss: 2063.0356 - accuracy: 0.0141\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 2035.0732 - accuracy: 0.0141\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 2005.5729 - accuracy: 0.0141\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1975.9323 - accuracy: 0.0141\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1945.3838 - accuracy: 0.0141\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 971us/step - loss: 1913.7966 - accuracy: 0.0141\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1881.1930 - accuracy: 0.0141\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1847.5519 - accuracy: 0.0141\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1814.0724 - accuracy: 0.0141\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1780.3716 - accuracy: 0.0141\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1746.5460 - accuracy: 0.0141\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1711.4102 - accuracy: 0.0141\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1675.9980 - accuracy: 0.0141\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 1000us/step - loss: 1641.2140 - accuracy: 0.0141\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 971us/step - loss: 1606.0953 - accuracy: 0.0141\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1569.8518 - accuracy: 0.0141\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 1536.0829 - accuracy: 0.0141\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1502.0370 - accuracy: 0.0141\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1468.5017 - accuracy: 0.0141\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1434.5809 - accuracy: 0.0141\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1401.8174 - accuracy: 0.0141\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1368.5294 - accuracy: 0.0141\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 1336.3024 - accuracy: 0.0141\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1304.5193 - accuracy: 0.0141\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1273.7109 - accuracy: 0.0141\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1242.7723 - accuracy: 0.0141\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1213.4637 - accuracy: 0.0141\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1185.7134 - accuracy: 0.0141\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 971us/step - loss: 1157.2072 - accuracy: 0.0141\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1130.4901 - accuracy: 0.0141\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1103.8032 - accuracy: 0.0141\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 1077.8732 - accuracy: 0.0141\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 857us/step - loss: 1053.1155 - accuracy: 0.0141\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 1029.3053 - accuracy: 0.0141\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 1005.9723 - accuracy: 0.0141\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 984.9033 - accuracy: 0.0141\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 962.2678 - accuracy: 0.0141\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 941.4726 - accuracy: 0.0141\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 922.8417 - accuracy: 0.0141\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 902.9149 - accuracy: 0.0141\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 885.0073 - accuracy: 0.0141\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 868.0587 - accuracy: 0.0141\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 851.3759 - accuracy: 0.0141\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 835.7363 - accuracy: 0.0141\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 820.5463 - accuracy: 0.0141\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 807.3750 - accuracy: 0.0141\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 793.4316 - accuracy: 0.0141\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 781.6850 - accuracy: 0.0141\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 768.0026 - accuracy: 0.0141\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 756.9702 - accuracy: 0.0141\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 746.8099 - accuracy: 0.0141\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 736.7543 - accuracy: 0.0141\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 727.1946 - accuracy: 0.0141\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 719.0139 - accuracy: 0.0141\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 710.9273 - accuracy: 0.0141\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 702.7307 - accuracy: 0.0141\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 695.6581 - accuracy: 0.0141\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 689.0208 - accuracy: 0.0141\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 682.2928 - accuracy: 0.0141\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 676.1906 - accuracy: 0.0141\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 670.4753 - accuracy: 0.0141\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 664.6280 - accuracy: 0.0141\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 971us/step - loss: 660.3026 - accuracy: 0.0141\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 655.0751 - accuracy: 0.0141\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 650.7863 - accuracy: 0.0141\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 647.1192 - accuracy: 0.0141\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 642.9597 - accuracy: 0.0141\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 639.8027 - accuracy: 0.0141\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 636.3074 - accuracy: 0.0141\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 633.2471 - accuracy: 0.0141\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 630.1988 - accuracy: 0.0141\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 627.6531 - accuracy: 0.0141\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 624.9351 - accuracy: 0.0141\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 622.5234 - accuracy: 0.0141\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 620.3622 - accuracy: 0.0141\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 618.8436 - accuracy: 0.0141\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 616.1756 - accuracy: 0.0141\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 943us/step - loss: 614.7608 - accuracy: 0.0141\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 612.5186 - accuracy: 0.0141\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 914us/step - loss: 611.0588 - accuracy: 0.0141\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 609.5154 - accuracy: 0.0141\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 607.8555 - accuracy: 0.0141\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 886us/step - loss: 606.7134 - accuracy: 0.0141\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 605.3863 - accuracy: 0.0141 \n",
      "1/1 [==============================] - 0s 110ms/step - loss: 563.6673 - accuracy: 0.0000e+00\n",
      "\n",
      "Model Evaluation - Loss: 563.6672973632812, Accuracy: 0.0\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "\n",
      "Prediction for new data: [[36.07064]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Membaca dataset dari file CSV\n",
    "df = pd.read_csv('cuaca.csv')\n",
    "\n",
    "# Membagi dataset menjadi fitur (X) dan target (y)\n",
    "X = df[['Hum', 'Temp']]\n",
    "y = df['Weather']\n",
    "\n",
    "# Membagi dataset menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisasi fitur menggunakan StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Membangun model ANN\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Mengompilasi model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=2, verbose=1)\n",
    "\n",
    "# Evaluasi model pada data uji\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'\\nModel Evaluation - Loss: {loss}, Accuracy: {accuracy}')\n",
    "\n",
    "# Membuat prediksi\n",
    "new_data = np.array([[80, 30]])  # Ganti dengan data yang ingin Anda prediksi\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "prediction = model.predict(new_data_scaled)\n",
    "print(f'\\nPrediction for new data: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 49ms/step - loss: 0.6568 - accuracy: 0.1616 - val_loss: 0.5204 - val_accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4821 - accuracy: 0.2323 - val_loss: 0.3602 - val_accuracy: 0.2000\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3214 - accuracy: 0.2323 - val_loss: 0.2039 - val_accuracy: 0.2000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1668 - accuracy: 0.2323 - val_loss: 0.0566 - val_accuracy: 0.2000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0212 - accuracy: 0.2323 - val_loss: -0.0800 - val_accuracy: 0.2000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.1107 - accuracy: 0.2323 - val_loss: -0.2199 - val_accuracy: 0.2000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -0.2467 - accuracy: 0.2323 - val_loss: -0.3545 - val_accuracy: 0.2000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.3804 - accuracy: 0.2323 - val_loss: -0.4868 - val_accuracy: 0.2000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.5065 - accuracy: 0.2323 - val_loss: -0.6285 - val_accuracy: 0.2000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.6470 - accuracy: 0.2323 - val_loss: -0.7723 - val_accuracy: 0.2000\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 48ms/step - loss: 0.8902 - accuracy: 0.3434 - val_loss: 0.7854 - val_accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7242 - accuracy: 0.3232 - val_loss: 0.6160 - val_accuracy: 0.2400\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5648 - accuracy: 0.2222 - val_loss: 0.4574 - val_accuracy: 0.2400\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4179 - accuracy: 0.2222 - val_loss: 0.2912 - val_accuracy: 0.2400\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2727 - accuracy: 0.2222 - val_loss: 0.1298 - val_accuracy: 0.2400\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1395 - accuracy: 0.2222 - val_loss: -0.0273 - val_accuracy: 0.2400\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0106 - accuracy: 0.2222 - val_loss: -0.1660 - val_accuracy: 0.2400\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.1171 - accuracy: 0.2222 - val_loss: -0.2986 - val_accuracy: 0.2400\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.2398 - accuracy: 0.2222 - val_loss: -0.4319 - val_accuracy: 0.2400\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.3728 - accuracy: 0.2222 - val_loss: -0.5626 - val_accuracy: 0.2400\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000233E048D4E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 48ms/step - loss: 0.6493 - accuracy: 0.1515 - val_loss: 0.5069 - val_accuracy: 0.2400\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4603 - accuracy: 0.2222 - val_loss: 0.3102 - val_accuracy: 0.2400\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2791 - accuracy: 0.2222 - val_loss: 0.1278 - val_accuracy: 0.2400\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1150 - accuracy: 0.2222 - val_loss: -0.0468 - val_accuracy: 0.2400\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.0388 - accuracy: 0.2222 - val_loss: -0.2122 - val_accuracy: 0.2400\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.1900 - accuracy: 0.2222 - val_loss: -0.3703 - val_accuracy: 0.2400\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.3330 - accuracy: 0.2222 - val_loss: -0.5211 - val_accuracy: 0.2400\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.4730 - accuracy: 0.2222 - val_loss: -0.6760 - val_accuracy: 0.2400\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.6248 - accuracy: 0.2222 - val_loss: -0.8406 - val_accuracy: 0.2400\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.7855 - accuracy: 0.2222 - val_loss: -1.0240 - val_accuracy: 0.2400\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000233E05ECAE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 48ms/step - loss: 0.9348 - accuracy: 0.2323 - val_loss: 0.7982 - val_accuracy: 0.4400\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7308 - accuracy: 0.2929 - val_loss: 0.6454 - val_accuracy: 0.4400\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5565 - accuracy: 0.3232 - val_loss: 0.5090 - val_accuracy: 0.4400\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3921 - accuracy: 0.3333 - val_loss: 0.3756 - val_accuracy: 0.2400\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2370 - accuracy: 0.2222 - val_loss: 0.2482 - val_accuracy: 0.2400\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0804 - accuracy: 0.2222 - val_loss: 0.1266 - val_accuracy: 0.2400\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: -0.0684 - accuracy: 0.2222 - val_loss: 0.0022 - val_accuracy: 0.2400\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.2253 - accuracy: 0.2222 - val_loss: -0.1310 - val_accuracy: 0.2400\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.3979 - accuracy: 0.2222 - val_loss: -0.2689 - val_accuracy: 0.2400\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.5732 - accuracy: 0.2222 - val_loss: -0.4109 - val_accuracy: 0.2400\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 49ms/step - loss: 0.7025 - accuracy: 0.0900 - val_loss: 0.6357 - val_accuracy: 0.2083\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5268 - accuracy: 0.0900 - val_loss: 0.4857 - val_accuracy: 0.2083\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3816 - accuracy: 0.0900 - val_loss: 0.3446 - val_accuracy: 0.2083\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2423 - accuracy: 0.0900 - val_loss: 0.2043 - val_accuracy: 0.2083\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1039 - accuracy: 0.1600 - val_loss: 0.0655 - val_accuracy: 0.2083\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.0290 - accuracy: 0.2300 - val_loss: -0.0648 - val_accuracy: 0.2083\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.1657 - accuracy: 0.2300 - val_loss: -0.2005 - val_accuracy: 0.2083\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.3036 - accuracy: 0.2300 - val_loss: -0.3402 - val_accuracy: 0.2083\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.4447 - accuracy: 0.2300 - val_loss: -0.4904 - val_accuracy: 0.2083\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: -0.6038 - accuracy: 0.2300 - val_loss: -0.6483 - val_accuracy: 0.2083\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Average Accuracy: 0.22566666666666663\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Membaca dataset dari file CSV\n",
    "file_path = 'cuaca.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Memilih fitur dan target\n",
    "X = dataset[['Hum', 'Temp']]\n",
    "y = dataset['Weather']\n",
    "\n",
    "# Menggunakan LabelEncoder untuk mengonversi label kategori menjadi bilangan bulat\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Normalisasi fitur menggunakan StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Melakukan oversampling pada seluruh dataset\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "# Membagi dataset menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # Membangun model ANN sederhana\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=(2,)),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Kompilasi model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Melatih model pada data latih fold\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, validation_data=(X_val_fold, y_val_fold))\n",
    "\n",
    "    # Evaluasi model pada data uji\n",
    "    y_pred_fold = model.predict(X_val_fold)\n",
    "    y_pred_fold_classes = (y_pred_fold > 0.5).astype(int).flatten()\n",
    "    accuracy_fold = accuracy_score(y_val_fold, y_pred_fold_classes)\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "\n",
    "# Menampilkan rata-rata akurasi dari seluruh fold\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(f'Average Accuracy: {average_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 73ms/step - loss: -0.1432 - accuracy: 0.0141 - val_loss: -3.0178 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -3.3571 - accuracy: 0.0141 - val_loss: -6.7051 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -6.6474 - accuracy: 0.0141 - val_loss: -10.5594 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -9.8558 - accuracy: 0.0141 - val_loss: -14.4303 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -13.1789 - accuracy: 0.0141 - val_loss: -18.2441 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -16.6314 - accuracy: 0.0141 - val_loss: -22.2775 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -20.1583 - accuracy: 0.0141 - val_loss: -26.6651 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -24.0088 - accuracy: 0.0141 - val_loss: -31.2731 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: -27.9159 - accuracy: 0.0141 - val_loss: -36.2746 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: -32.1506 - accuracy: 0.0141 - val_loss: -41.6465 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "==================================================\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      1.00      0.00       0.0\n",
      "           3       1.00      0.00      0.00       4.0\n",
      "          60       1.00      0.00      0.00      11.0\n",
      "          61       1.00      0.00      0.00       1.0\n",
      "          63       1.00      0.00      0.00       2.0\n",
      "\n",
      "    accuracy                           1.00      18.0\n",
      "   macro avg       0.80      0.20      0.00      18.0\n",
      "weighted avg       1.00      0.00      0.00      18.0\n",
      "\n",
      "==================================================\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  0  0]\n",
      " [ 4  0  0  0  0]\n",
      " [11  0  0  0  0]\n",
      " [ 1  0  0  0  0]\n",
      " [ 2  0  0  0  0]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Baca dataset dari cuaca.csv\n",
    "df = pd.read_csv('cuaca.csv')\n",
    "\n",
    "# Label encoding untuk kolom Hum dan Temp\n",
    "columns_to_encode = ['Hum', 'Temp']\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Menggunakan weather sebagai output\n",
    "X = df.drop('Weather', axis=1)\n",
    "y = df['Weather']\n",
    "\n",
    "# Train test split untuk training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Menormalisasikan dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Inisialisasi model ANN\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model ANN dengan parameter\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model ANN\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "# Evaluasi model pada set pengujian\n",
    "y_test_pred_probs = model.predict(X_test_scaled)\n",
    "y_test_pred = (y_test_pred_probs > 0.5).astype(int)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=1))\n",
    "\n",
    "# Evaluasi matrix confusion\n",
    "print(\"=\"*50)\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "c:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'activation': 'relu', 'optimizer': 'adam'}\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Estimator needs to be fit before `predict` can be called",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_result\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Evaluasi model sebelum tuning\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m y_test_pred_before \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report (Before Tuning):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:1048\u001b[0m, in \u001b[0;36mBaseWrapper.predict\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns predictions for the given test data.\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \n\u001b[0;32m   1026\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;124;03m    Predictions, of shape shape (n_samples,) or (n_samples, n_outputs).\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;66;03m# predict with Keras model\u001b[39;00m\n\u001b[1;32m-> 1048\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;66;03m# post process y\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_encoder_\u001b[38;5;241m.\u001b[39minverse_transform(y_pred)\n",
      "File \u001b[1;32mc:\\Users\\VANZ\\Downloads\\tubes siscer\\.venv\\Lib\\site-packages\\scikeras\\wrappers.py:990\u001b[0m, in \u001b[0;36mBaseWrapper._predict_raw\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# check if fitted\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized_:\n\u001b[1;32m--> 990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator needs to be fit before `predict` \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan be called\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m     )\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# basic input checks\u001b[39;00m\n\u001b[0;32m    994\u001b[0m X, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Estimator needs to be fit before `predict` can be called"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier  # Import from scikeras\n",
    "\n",
    "# Fungsi untuk membuat model\n",
    "def create_model(optimizer='adam', activation='relu', dropout_rate=0.0):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation=activation))\n",
    "  model.add(Dropout(dropout_rate))\n",
    "  model.add(Dense(32, activation=activation))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "# Baca dataset dari cuaca.csv\n",
    "df = pd.read_csv('cuaca.csv')\n",
    "\n",
    "# Label encoding untuk kolom Hum dan Temp (jika diperlukan)\n",
    "columns_to_encode = ['Hum', 'Temp']  # Pastikan kolom ini berisi data kategorikal\n",
    "label_encoder = LabelEncoder()\n",
    "for column in columns_to_encode:\n",
    "  df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Menggunakan STATUS sebagai output\n",
    "X = df.drop('Weather', axis=1)\n",
    "y = df['Weather']\n",
    "\n",
    "# Train test split untuk training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Menormalisasikan dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Membuat model dengan KerasClassifier dari scikeras\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0, activation='relu')  # Set activation here\n",
    "\n",
    "# Parameter yang akan dioptimalkan\n",
    "param_grid = {\n",
    "  'optimizer': ['adam', 'rmsprop'],\n",
    "  'activation': ['relu', 'tanh'],\n",
    "}\n",
    "\n",
    "# Melakukan Grid Search untuk tuning parameter\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "grid_result = grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Menampilkan parameter terbaik\n",
    "print(\"Best Parameters:\", grid_result.best_params_)\n",
    "\n",
    "# Menggunakan model terbaik dari Grid Search\n",
    "best_model = grid_result.best_estimator_\n",
    "\n",
    "# Evaluasi model sebelum tuning\n",
    "y_test_pred_before = model.predict(X_test_scaled)\n",
    "print(\"=\"*50)\n",
    "print(\"Classification Report (Before Tuning):\")\n",
    "print(classification_report(y_test, y_test_pred_before, zero_division=1))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_before))\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Evaluasi model setelah tuning\n",
    "y_test_pred_after = best_model.predict(X_test_scaled)\n",
    "print(\"=\"*50)\n",
    "print(\"Classification Report (After Tuning):\")\n",
    "print(classification_report(y_test, y_test_pred_after, zero_division=1))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_after))\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi testing: 0.16666666666666666\n",
      "Akurasi training: 0.4647887323943662\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Baca dataset cuaca.csv\n",
    "df = pd.read_csv('cuaca.csv')\n",
    "\n",
    "# Pilih kolom Temp dan Hum\n",
    "X = df[['Temp', 'Hum']]\n",
    "\n",
    "# Label encoding untuk kolom Weather\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Weather'])\n",
    "\n",
    "# Train test split untuk training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisasi dataset\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Buat model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Latih model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi data uji\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Hitung akurasi\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Cetak hasil testing\n",
    "print('Akurasi testing:', accuracy)\n",
    "\n",
    "# Cetak hasil training\n",
    "print('Akurasi training:', model.score(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi testing: 0.4444444444444444\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.75      0.60         4\n",
      "           2       0.83      0.45      0.59        11\n",
      "           3       0.00      0.00      1.00         1\n",
      "           4       1.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.44        18\n",
      "   macro avg       0.58      0.30      0.55        18\n",
      "weighted avg       0.73      0.44      0.55        18\n",
      "\n",
      "Confusion matrix:\n",
      " [[3 1 0 0]\n",
      " [2 5 4 0]\n",
      " [1 0 0 0]\n",
      " [0 0 2 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model.h5']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Baca dataset cuaca.csv\n",
    "df = pd.read_csv('cuaca.csv')\n",
    "\n",
    "# Pilih kolom Temp dan Hum\n",
    "X = df[['Temp', 'Hum']]\n",
    "\n",
    "# Label encoding untuk kolom Weather\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Weather'])\n",
    "\n",
    "# Train test split untuk training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisasi dataset\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Buat model\n",
    "model = SVC()\n",
    "\n",
    "# Latih model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi data uji\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Cetak hasil testing\n",
    "print('Akurasi testing:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Cetak classification report\n",
    "print('Classification report:\\n', classification_report(y_test, y_pred, zero_division=1))\n",
    "\n",
    "# Cetak confusion matrix\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Simpan model\n",
    "joblib.dump(model, 'model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
